{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2a7e1-5af4-4f10-8ec2-6f271ca91e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup\n",
    "!pip install spacy\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9209d99-12ce-4a7f-816c-9730da1c9eb0",
   "metadata": {},
   "source": [
    "To make this notebook work you need conda and do this in your environment: conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac59787-17d0-4e3e-a9e6-d42b5ce53555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datamodell for Spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c61cf-0d33-4f72-8025-d4ab167be03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddba333-da3d-4814-8185-d17b11b54193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSentimentOfEntities(sentence):\n",
    "    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    entity_sentiments = {}\n",
    "\n",
    "    # Analyze sentiment of each entity and its context\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in {\"PERSON\", \"ORG\"}:\n",
    "            # Extract surrounding context for the entity\n",
    "            entity_context = sentence[ent.start_char: ent.end_char + 20]\n",
    "            # Run the sentiment analysis on entity context\n",
    "            sentiment = sentiment_analyzer(entity_context)[0]\n",
    "            entity_sentiments[ent.text] = sentiment\n",
    "\n",
    "    return entity_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8d43a-e070-4c1c-bbb0-cc2651aed9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"LABEL_0\": \"negative\",\n",
    "    \"LABEL_1\": \"neutral\",\n",
    "    \"LABEL_2\": \"positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea853adf-26a5-4932-9520-362cf1f59244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelToReadableLabelConverter(entitySentiment):\n",
    "    # Define a mapping for labels to sentiment\n",
    "    interpreted_results = {}\n",
    "    for entity, result in entitySentiment.items():\n",
    "        label = result[\"label\"]\n",
    "        interpreted_label = label_mapping.get(label, \"unknown\")  # map label to sentiment\n",
    "        interpreted_results[entity] = {\n",
    "            \"sentiment\": interpreted_label,\n",
    "            \"score\": result[\"score\"]\n",
    "        }\n",
    "    return interpreted_results\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae1bd53-f74b-4005-a0b5-7f3e17b1eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests\n",
    "tests = list()\n",
    "tests.append(\"Harris is pretty good\")\n",
    "tests.append(\"Harris is the worst\")\n",
    "tests.append(\"Kamala Harris sucks\")\n",
    "tests.append(\"Donald Trump is a dump\")\n",
    "tests.append(\"Trump is the stupidest man i ever encountered, he is just a stupid dick with shit comments and bullshits all over the place\")\n",
    "tests.append(\"I love Trump and i want him to be president forever\")\n",
    "tests.append(\"Kamala and Trump are both horrible\")\n",
    "tests.append(\"I think Kamala and Trump are both good\")\n",
    "tests.append(\" fuck this system. Vote for Trump\")\n",
    "for test in tests:\n",
    "    analysis = computeSentimentOfEntities(test)\n",
    "    print(labelToReadableLabelConverter(analysis))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a4344-c7e3-4cc3-b891-9b205efc1047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0e1385-51c3-431d-915d-4eaebf6d763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675a09e-4a9d-470f-af7b-cea95a260456",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
